{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Initialize"
      ],
      "metadata": {
        "id": "SbDYseIAgd9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qplFb7NdF973"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Read a file from goofgle drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# After mounting, you can access files in your Google Drive.\n",
        "# For example, if you have a file named 'my_document.txt' in the root of your Drive:\n",
        "\n"
      ],
      "metadata": {
        "id": "e6B4iPjyG89U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined Dataset Creation"
      ],
      "metadata": {
        "id": "Hj_97DRYeLMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/drive/MyDrive/Amex/test_data.parquet'\n",
        "test_data = pd.read_parquet(test_path)\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "XrrFuv3FG_fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Amex/train_sample_20p.parquet' #'/content/drive/MyDrive/Amex/train_sample.parquet'\n",
        "train_data = pd.read_parquet(train_path)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "2TSKuaf9HN91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "LiO5nfp2-x31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_path = '/content/drive/MyDrive/Amex/add_event.parquet'\n",
        "event_data = pd.read_parquet(event_path)\n",
        "event_data.head()"
      ],
      "metadata": {
        "id": "vjzlCfvtHhIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, determine which DataFrame has which type and convert accordingly\n",
        "# For example, if train_data has 'id2' as object and events has 'id2' as int32:\n",
        "event_data['id2'] = event_data['id2'].astype(str)  # Convert int32 to string (object)"
      ],
      "metadata": {
        "id": "Dq4_Jdn5pYWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or alternatively, if you want to convert train_data's column to int:\n",
        "# train_data['id2'] = train_data['id2'].astype(int)\n",
        "\n",
        "# Then perform the merge\n",
        "train_df = pd.merge(\n",
        "    train_data,\n",
        "    event_data,\n",
        "    on=['id2', 'id3', 'id4'],  # Columns to join on\n",
        "    how='left'  # Type of join: 'inner', 'outer', 'left', 'right'\n",
        ")"
      ],
      "metadata": {
        "id": "nBFA1B3lIAQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then perform the merge\n",
        "test_df = pd.merge(\n",
        "    test_data,\n",
        "    event_data,\n",
        "    on=['id2', 'id3', 'id4'],  # Columns to join on\n",
        "    how='left'  # Type of join: 'inner', 'outer', 'left', 'right'\n",
        ")"
      ],
      "metadata": {
        "id": "HGTZbQFWoCxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)"
      ],
      "metadata": {
        "id": "x7ptO8NbjkF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.shape)"
      ],
      "metadata": {
        "id": "ydSoV0SLoYX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_parquet(r\"/content/drive/MyDrive/Amex/test_event.parquet\",index = True)"
      ],
      "metadata": {
        "id": "c_1nSkVL5B8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/drive/MyDrive/Amex/test_event.parquet'\n",
        "test_df = pd.read_parquet(test_path)\n"
      ],
      "metadata": {
        "id": "A7ZIH87R6Cxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "id": "sP7BYJRP3ceQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_path = '/content/drive/MyDrive/Amex/add_trans.parquet'\n",
        "trans_data = pd.read_parquet(trans_path)\n",
        "trans_data.head()"
      ],
      "metadata": {
        "id": "zFKWKUJQJXv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trans_data['f367'].unique())"
      ],
      "metadata": {
        "id": "mZ_Ai-29dslN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_data['id2'] = trans_data['id2'].astype(str)  # Convert int32 to string (object)"
      ],
      "metadata": {
        "id": "l13ljmCopyRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then perform the merge\n",
        "\n",
        "train_df = pd.merge(\n",
        "    train_df,\n",
        "    trans_data,\n",
        "    on=['id2'],  # Columns to join on\n",
        "    how='left'  # Type of join: 'inner', 'outer', 'left', 'right'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "IEqsbOskKEbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then perform the merge\n",
        "test_df = pd.merge(\n",
        "    test_df,\n",
        "    trans_data,\n",
        "    on=['id2'],  # Columns to join on\n",
        "    how='left'  # Type of join: 'inner', 'outer', 'left', 'right'\n",
        ")"
      ],
      "metadata": {
        "id": "ZxHeow5Gof8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(train_df.columns))"
      ],
      "metadata": {
        "id": "9i47xmJEKl1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(test_df.columns))"
      ],
      "metadata": {
        "id": "xIs1d2L_oiFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offer_path = '/content/drive/MyDrive/Amex/offer_metadata.parquet'\n",
        "offer_data = pd.read_parquet(offer_path)\n",
        "offer_data.head()"
      ],
      "metadata": {
        "id": "Rv_1497VLIkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unique f374 values\n",
        "\n",
        "print(train_df['f374'].unique())"
      ],
      "metadata": {
        "id": "6bRoJFR6LlqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df['f374'].unique())"
      ],
      "metadata": {
        "id": "EXlL9qlgnurL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop f374 from train_df\n",
        "\n",
        "train_df = train_df.drop('f374', axis=1)\n"
      ],
      "metadata": {
        "id": "Ib7la7AaMZDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop f374 from train_df\n",
        "\n",
        "test_df = test_df.drop('f374', axis=1)\n"
      ],
      "metadata": {
        "id": "YqWqfZnGowQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['id8'].unique())"
      ],
      "metadata": {
        "id": "SKmPgyf2iJoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop('id8', axis=1)\n"
      ],
      "metadata": {
        "id": "4EZozhInOG4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df['id8'].unique())"
      ],
      "metadata": {
        "id": "WT8LlZzbqBwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.drop('id8', axis=1)"
      ],
      "metadata": {
        "id": "rxUCu27iqH4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(train_df.columns))"
      ],
      "metadata": {
        "id": "7ItY4X4Xd-LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(test_df.columns))"
      ],
      "metadata": {
        "id": "4mNTdVdxqSwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)"
      ],
      "metadata": {
        "id": "gSeTY4m3kxzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.shape)"
      ],
      "metadata": {
        "id": "U4fHZS0gqaWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offer_data['id3'] = offer_data['id3'].astype(str)  # Convert int32 to string (object)"
      ],
      "metadata": {
        "id": "MWFYSB3cqnmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then perform the merge\n",
        "\n",
        "train_df = pd.merge(\n",
        "    train_df,\n",
        "    offer_data,\n",
        "    on=['id3'],  # Columns to join on\n",
        "    how='left'  # Type of join: 'inner', 'outer', 'left', 'right'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Kd6f38YmMsdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then perform the merge\n",
        "test_df = pd.merge(\n",
        "    test_df,\n",
        "    offer_data,\n",
        "    on=['id3'],  # Columns to join on\n",
        "    how='left'  # Type of join: 'inner', 'outer', 'left', 'right'\n",
        ")"
      ],
      "metadata": {
        "id": "i4Y3r4aUqq0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(train_df.columns))"
      ],
      "metadata": {
        "id": "wWnz1hRGlC4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(test_df.columns))"
      ],
      "metadata": {
        "id": "tk3bROWlqvZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)"
      ],
      "metadata": {
        "id": "6Ue-mNBYOt85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.shape)"
      ],
      "metadata": {
        "id": "bO3Zk1T6q6AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the values in 'id4' column with the hour of the day of the timestamp, the datatype of the column should be an object\n",
        "\n",
        "train_df['id4'] = pd.to_datetime(train_df['id4']).dt.hour.astype(str)"
      ],
      "metadata": {
        "id": "ujw8tE7m1D2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['id4'] = pd.to_datetime(test_df['id4']).dt.hour.astype(str)"
      ],
      "metadata": {
        "id": "SswdX2Bm1YIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_parquet(r\"/content/drive/MyDrive/Amex/train_combined_sample_20p.parquet\",index = True)#(r\"/content/drive/MyDrive/Amex/train_combined_sample.parquet\",index = True)\n"
      ],
      "metadata": {
        "id": "N78C6IAdO3di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_parquet(r\"/content/drive/MyDrive/Amex/test_combined.parquet\",index = True)"
      ],
      "metadata": {
        "id": "wYn6B3KSrBaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p39II3n6eHTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Dataset"
      ],
      "metadata": {
        "id": "-ccx__9bPkgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read the train_data using dask\n",
        "train_path = '/content/drive/MyDrive/Amex/train_data.parquet'\n",
        "train_data = pd.read_parquet(train_path)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "OcKxC5ZxPj67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(train_data.dtypes))"
      ],
      "metadata": {
        "id": "OmNylr8gP8Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying K-Mean Clustering"
      ],
      "metadata": {
        "id": "bVZeKrwYYlEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of features to convert (truncated for clarity here; use full list below)\n",
        "numerical_cols = [\n",
        "    'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
        "    'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20',\n",
        "    'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30',\n",
        "    'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40',\n",
        "    'f41', 'f43', 'f44', 'f45', 'f46', 'f47', 'f49', 'f51', 'f58', 'f59',\n",
        "    'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69',\n",
        "    'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79',\n",
        "    'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89',\n",
        "    'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99',\n",
        "    'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108',\n",
        "    'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117',\n",
        "    'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126',\n",
        "    'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135',\n",
        "    'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144',\n",
        "    'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153',\n",
        "    'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162',\n",
        "    'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171',\n",
        "    'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180',\n",
        "    'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189',\n",
        "    'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198',\n",
        "    'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207',\n",
        "    'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216',\n",
        "    'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225',\n",
        "    'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318',\n",
        "    'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327',\n",
        "    'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336',\n",
        "    'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345',\n",
        "    'f346', 'f347', 'f348', 'f350', 'f351', 'f352', 'f353', 'f355', 'f356',\n",
        "    'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365',\n",
        "    'f366'\n",
        "]\n"
      ],
      "metadata": {
        "id": "OgoCaKGyQIdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to train dataframes\n",
        "for col in numerical_cols:\n",
        "    if col in train_data.columns:\n",
        "        train_data[col] = pd.to_numeric(train_data[col], errors='coerce')\n"
      ],
      "metadata": {
        "id": "oBFlQiFdQ_Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data[numerical_cols].fillna(0)"
      ],
      "metadata": {
        "id": "LBSAGHopdYGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "kmeans = MiniBatchKMeans(\n",
        "    n_clusters=100,\n",
        "    batch_size=10000,\n",
        "    max_iter=100,\n",
        "    random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "4VkEzDkgV4ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "B4Xjvom3cpbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fill missing and scale\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Reduce to 20 dimensions before clustering\n",
        "pca = PCA(n_components=20, random_state=42)\n",
        "X_reduced = pca.fit_transform(X_scaled)\n"
      ],
      "metadata": {
        "id": "7ktG0R0fX33y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_small = X.sample(n=100_000, random_state=42)  # or stratified sample\n",
        "X_scaled_small = StandardScaler().fit_transform(X_small.fillna(0))\n",
        "X_reduced_small = PCA(n_components=20).fit_transform(X_scaled_small)\n",
        "\n"
      ],
      "metadata": {
        "id": "U0D_GzsYbp7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(X_reduced_small)\n",
        "\n",
        "# Assign clusters to full data (if needed)\n",
        "X_full_scaled = StandardScaler().fit_transform(X.fillna(0))\n",
        "X_full_reduced = PCA(n_components=20).fit_transform(X_full_scaled)\n"
      ],
      "metadata": {
        "id": "O59CXQE0dKzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['cluster'] = kmeans.predict(X_full_reduced)"
      ],
      "metadata": {
        "id": "xc74qFJefcoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "oiaqoWP_wEA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "0rJ2DRzKwJpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#All Clicks + Sampled Non Clicks"
      ],
      "metadata": {
        "id": "Sl_eJNGfZVJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['y'].dtype"
      ],
      "metadata": {
        "id": "FMHsJsqYaCw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Keep all clicks (positives)\n",
        "clicks = train_data[train_data['y'] == '1']\n",
        "\n",
        "# 2. Randomly sample a fraction of non-clicks (negatives)\n",
        "non_clicks_sampled = train_data[train_data['y'] == '0'].sample(frac=0.25, random_state=42)\n",
        "\n",
        "# 3. Combine and shuffle\n",
        "train_sample = pd.concat([clicks, non_clicks_sampled]).sample(frac=1.0, random_state=42).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "zXl8xA0pZgJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample.shape"
      ],
      "metadata": {
        "id": "47Z02DsDZ5Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample.to_parquet(r\"/content/drive/MyDrive/Amex/train_sample_25p.parquet\",index = True)"
      ],
      "metadata": {
        "id": "C2vMtA0sb1iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stratified Sampling"
      ],
      "metadata": {
        "id": "e-Rcd51pxvU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Stratified sample (e.g., 10% of train_data)\n",
        "train_sample, _ = train_test_split(\n",
        "    train_data,\n",
        "    test_size=0.80,  # or use train_size=0.10\n",
        "    stratify=train_data['y'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Sampled data shape:\", train_sample.shape)\n",
        "print(train_sample['y'].value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "ulvZeto-x3IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample.to_parquet(r\"/content/drive/MyDrive/Amex/train_sample_20p.parquet\",index = True)"
      ],
      "metadata": {
        "id": "7JmmDq90zWvG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}